{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4b5e882",
      "metadata": {
        "id": "f4b5e882"
      },
      "source": [
        "\n",
        "## 0) Постановка задачи\n",
        "\n",
        "Предсказать отказ компонента пневмосистемы (APS) по телеметрии датчиков грузовиков. Это бинарная классификация: pos — целевой отказ APS; neg — другие поломки. В официальной постановке есть стоимость ошибок: FP=10, FN=500 — пропуск «плохого» грузовика сильно дороже ложной тревоги.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a97b9d",
      "metadata": {
        "id": "e0a97b9d"
      },
      "source": [
        "## 1) Чтение данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2fba16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "bf2fba16",
        "outputId": "123cc9ef-0855-4f93-e0db-664bf2f679c7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/aps_failure_training_set.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1441834313.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_aps_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mdf_test_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_aps_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1441834313.py\u001b[0m in \u001b[0;36mread_aps_csv\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"\"\"Читает CSV APS, пропуская преамбулу лицензии до строки 'class,....'\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mheader_line_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class,\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/aps_failure_training_set.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_path = \"/mnt/data/aps_failure_training_set.csv\"\n",
        "test_path  = \"/mnt/data/aps_failure_test_set.csv\"\n",
        "\n",
        "def read_aps_csv(path):\n",
        "    \"\"\"Читает CSV APS, пропуская преамбулу лицензии до строки 'class,....'\"\"\"\n",
        "    header_line_idx = None\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            if line.lower().startswith(\"class,\"):\n",
        "                header_line_idx = idx\n",
        "                break\n",
        "    if header_line_idx is None:\n",
        "        raise RuntimeError(\"Не найден заголовок 'class,...' в файле \" + path)\n",
        "    df = pd.read_csv(path, na_values=[\"na\"], skiprows=header_line_idx, header=0)\n",
        "    return df\n",
        "\n",
        "df = read_aps_csv(train_path)\n",
        "df_test_raw = read_aps_csv(test_path)\n",
        "\n",
        "print(\"TRAIN shape:\", df.shape)\n",
        "print(\"TEST shape:\", df_test_raw.shape)\n",
        "print(\"Columns sample:\", df.columns[:10].tolist())\n",
        "\n",
        "y = (df[\"class\"] == \"pos\").astype(int).rename(\"TARGET\")\n",
        "X = df.drop(columns=[\"class\"])\n",
        "\n",
        "N, d = X.shape\n",
        "print(f\"N={N}, d={d}, positive_rate={y.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9bb382",
      "metadata": {
        "id": "7a9bb382"
      },
      "source": [
        "## 2) Разбиение на обучающую/тестовую"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f6256c",
      "metadata": {
        "id": "39f6256c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "234805a2",
      "metadata": {
        "id": "234805a2"
      },
      "source": [
        "## 3) EDA: визуализация и основные характеристики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb2cf2b",
      "metadata": {
        "id": "0cb2cf2b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 3.1 Class distribution\n",
        "counts = y.value_counts().sort_index()\n",
        "plt.figure()\n",
        "plt.bar(['neg(0)', 'pos(1)'], [counts.get(0,0), counts.get(1,0)])\n",
        "plt.title(\"Распределение классов (весь TRAIN)\")\n",
        "plt.xlabel(\"Класс\")\n",
        "plt.ylabel(\"Число объектов\")\n",
        "plt.show()\n",
        "\n",
        "# 3.2 Missing by feature\n",
        "missing_rate = X.isna().mean().sort_values(ascending=False)\n",
        "print(\"Топ-20 признаков по доле пропусков:\")\n",
        "print(missing_rate.head(20))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(missing_rate)), missing_rate.values)\n",
        "plt.title(\"Доля пропусков по признакам (отсортировано)\")\n",
        "plt.xlabel(\"Признаки (индекс после сортировки)\")\n",
        "plt.ylabel(\"Доля пропусков\")\n",
        "plt.show()\n",
        "\n",
        "# 3.3 Descriptives (head)\n",
        "desc = X.describe().T\n",
        "display(desc.head(15))\n",
        "\n",
        "# 3.4 Top-15 pairwise correlations\n",
        "corr = X.corr(method=\"pearson\", min_periods=1)\n",
        "vals = []\n",
        "cols = corr.columns\n",
        "for i in range(len(cols)):\n",
        "    for j in range(i+1, len(cols)):\n",
        "        v = corr.iloc[i, j]\n",
        "        if not np.isnan(v):\n",
        "            vals.append((cols[i], cols[j], abs(v), v))\n",
        "top_corr = sorted(vals, key=lambda x: x[2], reverse=True)[:15]\n",
        "print(\"Топ-15 пар по |corr|:\")\n",
        "for a,b,absv,v in top_corr:\n",
        "    print(f\"{a:>8s} ~ {b:<8s} |corr|={absv:.3f}, corr={v:.3f}\")\n",
        "\n",
        "# 3.5 Rough outlier rate via IQR*3 on any feature\n",
        "def row_outlier_mask(df_num):\n",
        "    mask_any = np.zeros(len(df_num), dtype=bool)\n",
        "    for col in df_num.columns:\n",
        "        s = df_num[col]\n",
        "        q1 = s.quantile(0.25)\n",
        "        q3 = s.quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        if pd.isna(iqr) or iqr == 0:\n",
        "            continue\n",
        "        low = q1 - 3 * iqr\n",
        "        high = q3 + 3 * iqr\n",
        "        m = (s < low) | (s > high)\n",
        "        mask_any |= m.fillna(False).to_numpy()\n",
        "    return mask_any\n",
        "\n",
        "outlier_mask = row_outlier_mask(X)\n",
        "print(f\"Оценка доли строк-выбросов (IQR*3, ≥1 фиче): {outlier_mask.mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "083dd2b8",
      "metadata": {
        "id": "083dd2b8"
      },
      "source": [
        "## 4–6) Предобработка: пропуски → median, категориальных в X нет, нормализация StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b18a0b",
      "metadata": {
        "id": "a2b18a0b"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "preproc = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bff06da",
      "metadata": {
        "id": "6bff06da"
      },
      "source": [
        "## 7) Базовый классификатор и аргументация выбора"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e809da",
      "metadata": {
        "id": "a5e809da"
      },
      "source": [
        "\n",
        "Используем **LogisticRegression (class_weight='balanced')**:\n",
        "\n",
        "* Быстро и даёт вероятности → удобно **настраивать порог** под несимметричные стоимости ошибок.\n",
        "* Устойчива и интерпретируема.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ea60d9",
      "metadata": {
        "id": "05ea60d9"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Fast training subset\n",
        "FAST_MODE = True\n",
        "NEG_SAMPLE = 6000\n",
        "\n",
        "def make_train_subset(X_tr, y_tr, neg_sample=NEG_SAMPLE):\n",
        "    df_tr = X_tr.copy()\n",
        "    df_tr[\"TARGET\"] = y_tr.values\n",
        "    pos = df_tr[df_tr[\"TARGET\"] == 1]\n",
        "    neg = df_tr[df_tr[\"TARGET\"] == 0].sample(n=neg_sample, random_state=42)\n",
        "    sub = pd.concat([pos, neg], axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "    y_sub = sub[\"TARGET\"].astype(int)\n",
        "    X_sub = sub.drop(columns=[\"TARGET\"])\n",
        "    return X_sub, y_sub\n",
        "\n",
        "if FAST_MODE:\n",
        "    X_sub, y_sub = make_train_subset(X_train, y_train, NEG_SAMPLE)\n",
        "    print(\"FAST_MODE subset:\", X_sub.shape, \"pos_rate:\", y_sub.mean())\n",
        "else:\n",
        "    X_sub, y_sub = X_train, y_train\n",
        "    print(\"Full training:\", X_sub.shape)\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    (\"pre\", preproc),\n",
        "    (\"model\", LogisticRegression(max_iter=200, class_weight=\"balanced\", solver=\"lbfgs\"))\n",
        "])\n",
        "clf.fit(X_sub, y_sub)\n",
        "\n",
        "proba = clf.predict_proba(X_test)[:, 1]\n",
        "pred05 = (proba >= 0.5).astype(int)\n",
        "\n",
        "def report(y_true, y_pred, y_score):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    bacc = balanced_accuracy_score(y_true, y_pred)\n",
        "    auc = roc_auc_score(y_true, y_score)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "    print(f\"Accuracy={acc:.4f}, BalancedAcc={bacc:.4f}, ROC AUC={auc:.4f}\")\n",
        "    print(\"Confusion matrix (labels=[0,1]):\n",
        "\", cm)\n",
        "    return acc, bacc, auc, cm\n",
        "\n",
        "print(\"== LogisticRegression, threshold=0.5 ==\")\n",
        "acc, bacc, auc, cm = report(y_test, pred05, proba)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00cdf6d",
      "metadata": {
        "id": "e00cdf6d"
      },
      "source": [
        "## 10) Борьба с дисбалансом: настройка порога по стоимости"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59c5f0e3",
      "metadata": {
        "id": "59c5f0e3"
      },
      "source": [
        "Оптимизируем порог по формуле `TotalCost = 10*FP + 500*FN`. Перебираем 0.01…0.99."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87731f0e",
      "metadata": {
        "id": "87731f0e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "COST_FP = 10\n",
        "COST_FN = 500\n",
        "\n",
        "thresholds = np.linspace(0.01, 0.99, 99)\n",
        "best = None\n",
        "\n",
        "for th in thresholds:\n",
        "    pred = (proba >= th).astype(int)\n",
        "    cm = confusion_matrix(y_test, pred, labels=[0,1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    total = COST_FP*fp + COST_FN*fn\n",
        "    if best is None or total < best[\"total\"]:\n",
        "        best = {\"th\": th, \"cm\": cm, \"total\": total}\n",
        "\n",
        "print(f\"Best threshold: {best['th']:.2f}, TotalCost={best['total']}\")\n",
        "print(\"Confusion matrix @best threshold:\n",
        "\", best[\"cm\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeca2575",
      "metadata": {
        "id": "eeca2575"
      },
      "source": [
        "## 9) (опц.) Другие модели и сравнение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7255e2a",
      "metadata": {
        "id": "d7255e2a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "results = []\n",
        "\n",
        "# KNN (на подвыборке)\n",
        "knn = Pipeline(steps=[(\"pre\", preproc), (\"model\", KNeighborsClassifier(n_neighbors=11, weights=\"distance\"))])\n",
        "knn.fit(X_sub, y_sub)\n",
        "proba_knn = knn.predict_proba(X_test)[:, 1]\n",
        "pred_knn = (proba_knn >= 0.5).astype(int)\n",
        "acc, bacc, auc, cm = report(y_test, pred_knn, proba_knn)\n",
        "results.append((\"KNN(k=11)\", acc, bacc, auc))\n",
        "\n",
        "# RandomForest (balanced_subsample)\n",
        "rf = Pipeline(steps=[(\"impute\", SimpleImputer(strategy=\"median\")),\n",
        "                    (\"model\", RandomForestClassifier(n_estimators=200, random_state=42,\n",
        "                                                    class_weight=\"balanced_subsample\", n_jobs=-1))])\n",
        "rf.fit(X_sub, y_sub)\n",
        "proba_rf = rf[\"model\"].predict_proba(rf[\"impute\"].transform(X_test))[:, 1]\n",
        "pred_rf = (proba_rf >= 0.5).astype(int)\n",
        "acc, bacc, auc, cm = report(y_test, pred_rf, proba_rf)\n",
        "results.append((\"RandomForest\", acc, bacc, auc))\n",
        "\n",
        "print(\"\\nSummary (test):\")\n",
        "for name, acc, bacc, auc in results:\n",
        "    print(f\"{name:15s}  Acc={acc:.4f}  BAcc={bacc:.4f}  AUC={auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f55e10b1",
      "metadata": {
        "id": "f55e10b1"
      },
      "source": [
        "## 12) Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c1b35a4",
      "metadata": {
        "id": "7c1b35a4"
      },
      "source": [
        "\n",
        "* Данные большие (60k×170), с множеством пропусков и сильным дисбалансом (≈1.7% `pos`).\n",
        "* Базовый конвейер **median-impute → scale → LogisticRegression(balanced)** даёт высокий **ROC AUC** и адекватную сбалансированную точность.\n",
        "* **Тюнинг порога** по стоимостной функции ожидаемо уменьшает общую стоимость за счёт повышения чувствительности к классу `pos`.\n",
        "* Дальнейшие шаги: градиентный бустинг, тщательное отбор/инженерия признаков, кросс-валидация порога и более продвинутые техники борьбы с дисбалансом (разбавление, SMOTE, focal loss и т.п.).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}